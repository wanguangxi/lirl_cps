{
  "Original": {
    "evaluation": {
      "mean_reward": 10287.433333333323,
      "std_reward": 1.8189894035458565e-12,
      "mean_travel_time": 1518.1680555555556,
      "std_travel_time": 0.0,
      "mean_throughput": 23918.0,
      "std_throughput": 0.0,
      "mean_violations": 0.0,
      "std_violations": 0.0,
      "mean_violation_rate": 0.0,
      "std_violation_rate": 0.0,
      "all_rewards": [
        10287.433333333325,
        10287.433333333325,
        10287.433333333325,
        10287.433333333325,
        10287.433333333325,
        10287.433333333325,
        10287.433333333325,
        10287.433333333325,
        10287.433333333325,
        10287.433333333325
      ],
      "all_travel_times": [
        1518.1680555555556,
        1518.1680555555556,
        1518.1680555555556,
        1518.1680555555556,
        1518.1680555555556,
        1518.1680555555556,
        1518.1680555555556,
        1518.1680555555556,
        1518.1680555555556,
        1518.1680555555556
      ],
      "all_throughputs": [
        23918,
        23918,
        23918,
        23918,
        23918,
        23918,
        23918,
        23918,
        23918,
        23918
      ],
      "all_violations": [
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      "all_violation_rates": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ]
    },
    "description": "Pre-trained model performance in original environment"
  },
  "Constrained (No Retrain)": {
    "evaluation": {
      "mean_reward": -3506.7333333333327,
      "std_reward": 0.0,
      "mean_travel_time": 1633.4053472222222,
      "std_travel_time": 0.0,
      "mean_throughput": 14643.0,
      "std_throughput": 0.0,
      "mean_violations": 0.0,
      "std_violations": 0.0,
      "mean_violation_rate": 0.0,
      "std_violation_rate": 0.0,
      "all_rewards": [
        -3506.7333333333327,
        -3506.7333333333327,
        -3506.7333333333327,
        -3506.7333333333327,
        -3506.7333333333327,
        -3506.7333333333327,
        -3506.7333333333327,
        -3506.7333333333327,
        -3506.7333333333327,
        -3506.7333333333327
      ],
      "all_travel_times": [
        1633.4053472222222,
        1633.4053472222222,
        1633.4053472222222,
        1633.4053472222222,
        1633.4053472222222,
        1633.4053472222222,
        1633.4053472222222,
        1633.4053472222222,
        1633.4053472222222,
        1633.4053472222222
      ],
      "all_throughputs": [
        14643,
        14643,
        14643,
        14643,
        14643,
        14643,
        14643,
        14643,
        14643,
        14643
      ],
      "all_violations": [
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      "all_violation_rates": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ]
    },
    "description": "Accident at intersection_1_1, only modified action projection"
  },
  "Constrained (Transfer)": {
    "evaluation": {
      "mean_reward": 12604.500000000002,
      "std_reward": 0.0,
      "mean_travel_time": 1493.4383333333333,
      "std_travel_time": 0.0,
      "mean_throughput": 26185.0,
      "std_throughput": 0.0,
      "mean_violations": 0.0,
      "std_violations": 0.0,
      "mean_violation_rate": 0.0,
      "std_violation_rate": 0.0,
      "all_rewards": [
        12604.500000000002,
        12604.500000000002,
        12604.500000000002,
        12604.500000000002,
        12604.500000000002,
        12604.500000000002,
        12604.500000000002,
        12604.500000000002,
        12604.500000000002,
        12604.500000000002
      ],
      "all_travel_times": [
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333
      ],
      "all_throughputs": [
        26185,
        26185,
        26185,
        26185,
        26185,
        26185,
        26185,
        26185,
        26185,
        26185
      ],
      "all_violations": [
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      "all_violation_rates": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ]
    },
    "transfer_learning": {
      "episode_rewards": [
        -15160.066666666666,
        -20983.866666666658,
        -17624.266666666663,
        -20217.13333333329,
        -16991.100000000006,
        -18021.33333333336,
        -13702.766666666636,
        -12176.500000000004,
        -18014.933333333316,
        -17045.60000000002,
        -19235.066666666688,
        -14865.433333333316,
        -17829.06666666666,
        -18218.43333333335,
        -7725.200000000004,
        -8933.366666666663,
        -21320.066666666637,
        -15460.133333333351,
        -7218.466666666664,
        -11918.933333333332,
        -7383.53333333333,
        -11810.23333333333,
        -10012.066666666658,
        -13619.000000000027,
        -16767.400000000005,
        -11020.733333333324,
        -19837.866666666687,
        -10898.9,
        -12828.466666666676,
        -5514.266666666661,
        -12981.166666666662,
        -12807.366666666645,
        -16453.93333333337,
        -9466.233333333343,
        -17458.16666666669,
        -16820.300000000017,
        -12781.233333333317,
        -4615.633333333335,
        -9321.466666666665,
        -13165.166666666666,
        -17212.233333333355,
        -5488.333333333332,
        -2756.4333333333398,
        -8270.533333333336,
        -15655.866666666683,
        2312.5666666666675,
        -7084.100000000005,
        -4735.5000000000055,
        -2559.999999999998,
        -6514.766666666663,
        -13575.93333333333,
        4027.7333333333363,
        -13307.400000000023,
        -833.7666666666659,
        6604.733333333336,
        3712.7333333333463,
        -7613.599999999999,
        -15526.7,
        2719.8666666666677,
        71.63333333333367,
        2009.366666666668,
        -5793.566666666665,
        6506.766666666683,
        -3975.6999999999975,
        8893.933333333338,
        6946.200000000002,
        9429.833333333341,
        12079.900000000003,
        12591.500000000002,
        12437.200000000003,
        11334.466666666669,
        12604.500000000002,
        12559.366666666667,
        12604.500000000002,
        12604.500000000002,
        12604.500000000002,
        12604.500000000002,
        12604.500000000002,
        12604.500000000002,
        12604.500000000002,
        12584.566666666671,
        12604.500000000002,
        12508.600000000008,
        12604.500000000002,
        12584.56666666667,
        12604.500000000002,
        12071.166666666672,
        12604.500000000002,
        12415.000000000005,
        12604.500000000002,
        12604.500000000002,
        12604.500000000002
      ],
      "episode_travel_times": [
        1756.3803125,
        1778.1970833333332,
        1742.193576388889,
        1772.4270833333333,
        1741.1777430555555,
        1737.7876041666666,
        1703.1171875,
        1694.6847222222223,
        1751.7183333333332,
        1739.1284027777779,
        1759.6182986111112,
        1697.5675694444444,
        1756.082048611111,
        1737.0253819444445,
        1674.2663194444444,
        1692.751701388889,
        1774.5702083333333,
        1715.996388888889,
        1640.8267361111111,
        1686.0038194444444,
        1599.0368055555555,
        1683.0965972222223,
        1669.3807638888889,
        1677.9911458333333,
        1725.8452083333334,
        1647.4747222222222,
        1764.1764236111112,
        1680.9719444444445,
        1719.273888888889,
        1598.4654861111112,
        1687.7392708333334,
        1721.8680555555557,
        1707.704548611111,
        1637.5922916666666,
        1730.2759722222222,
        1734.765138888889,
        1721.970625,
        1617.5848958333333,
        1679.8527083333333,
        1686.6291319444445,
        1724.2264236111112,
        1631.5847916666667,
        1630.3816666666667,
        1680.2489930555555,
        1697.9725694444444,
        1545.4741666666666,
        1642.4615972222223,
        1585.5578819444445,
        1582.375625,
        1661.1159722222221,
        1697.459513888889,
        1563.2840972222223,
        1675.6089930555556,
        1580.281736111111,
        1525.6755208333334,
        1546.385486111111,
        1637.8748611111112,
        1708.2759722222222,
        1542.0586805555556,
        1577.9922916666667,
        1547.3322916666666,
        1600.2080902777777,
        1512.3384027777777,
        1601.0083333333334,
        1500.8756944444444,
        1509.5475694444444,
        1499.6438888888888,
        1494.048298611111,
        1493.4490972222222,
        1493.8109722222223,
        1502.8644444444444,
        1493.4383333333333,
        1493.6646180555556,
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333,
        1493.5647222222221,
        1493.4383333333333,
        1493.7638194444444,
        1493.4383333333333,
        1493.5647222222221,
        1493.4383333333333,
        1497.6875,
        1493.4383333333333,
        1493.6172569444445,
        1493.4383333333333,
        1493.4383333333333,
        1493.4383333333333
      ],
      "episode_throughputs": [
        6440,
        1900,
        4651,
        2691,
        4251,
        4473,
        6644,
        8353,
        4242,
        4691,
        2763,
        6631,
        4157,
        4322,
        11891,
        10999,
        2166,
        6381,
        11770,
        9023,
        11937,
        8759,
        10202,
        7406,
        5260,
        9402,
        2856,
        9722,
        7778,
        13410,
        8220,
        7849,
        5363,
        10534,
        4770,
        4917,
        8045,
        14099,
        10828,
        7954,
        4518,
        13485,
        15444,
        11499,
        5881,
        19133,
        12144,
        13969,
        15547,
        12708,
        7844,
        20370,
        7869,
        16766,
        22181,
        19879,
        11946,
        6198,
        19395,
        17342,
        18543,
        13277,
        21733,
        14477,
        23662,
        22240,
        23924,
        25913,
        26180,
        26068,
        25396,
        26185,
        26170,
        26185,
        26185,
        26185,
        26185,
        26185,
        26185,
        26185,
        26185,
        26185,
        26171,
        26185,
        26185,
        26185,
        25845,
        26185,
        25999,
        26185,
        26185,
        26185
      ],
      "total_episodes": 92,
      "total_time": 1653.209133863449,
      "convergence_episode": 46,
      "convergence_time": 871.8990669250488,
      "final_throughput": 26147.8,
      "final_travel_time": 1493.4741180555557
    },
    "description": "Performance after transfer learning in constrained environment"
  }
}